import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import math
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse, Patch
from skimage.metrics import mean_squared_error
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE
from sklearn.metrics import mean_absolute_error, r2_score
# import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch_geometric.graphgym import optim as geom_optim
from graphData import graphDataset
from time import perf_counter as t
from torch_geometric.utils import dropout_adj
from torch_geometric.nn import GATConv
import os
from model import Encoder, GATModel, drop_feature
from models.model import Decoder
from scipy.stats import pearsonr
import seaborn as sns
def encoder_train(model: GATModel, x,
                  edge_index):  # edge_indexé€šå¸¸æ˜¯ä¸€ä¸ª [2, num_edges] å¤§å°çš„çŸ©é˜µ
    model.train()  # è®­ç»ƒæ¨¡å¼ encoder_model = GATModel=model
    encoder_optimizer.zero_grad()
    # epoch_counter += 1
    edge_index_1 = dropout_adj(edge_index, p=0.5)[0]  # åŸæ¥0.5
    edge_index_2 = dropout_adj(edge_index, p=0.5)[0]  # åŸæ¥0.6
    x_1 = drop_feature(x, 0.1)  # å®šä¹‰äº†ä¸¤ç§ä¸åŒçš„ä¸¢ç‰¹å¾æ¦‚ç‡ï¼Œç”¨äºä¸¤ä¸ªè§†å›¾
    x_2 = drop_feature(x, 0.15)  # 566åºåˆ—0.2å’Œ0.3å¥½#jiah1n1 0.2 0.3æ•ˆæœå¥½
    # åˆ†åˆ«ç”Ÿæˆä¸¤ä¸ªè§†å›¾èšåˆåçš„åµŒå…¥å‘é‡
    z1 = model(x_1, edge_index_1)
    z2 = model(x_2, edge_index_2)  # æ¨¡å‹çš„å‚æ•°å°±æ˜¯encoderçš„å‚æ•°å³èšåˆæ—¶çš„æƒé‡
    # è¿™é‡Œçš„z1z2æ˜¯GCNModelçš„è¾“å‡ºï¼Œæ²¡æœ‰ç»è¿‡projectionçš„å…¨è¿æ¥å±‚
    Contrastive_loss = model.loss(z1, z2,
                                  batch_size=0)  # è°ƒç”¨æ¨¡å‹çš„æŸå¤±å‡½æ•°è®¡ç®—ä¸¤ä¸ªè§†å›¾çš„åµŒå…¥å‘é‡ z1 å’Œ z2 ä¹‹é—´çš„æŸå¤±
    Contrastive_loss.backward()
    encoder_optimizer.step()  # ä¼˜åŒ–encoderç”ŸæˆåµŒå…¥å‘é‡è¿‡ç¨‹ä¸­çš„æƒé‡
    encoder_scheduler.step()
    return Contrastive_loss.item()


# === æ‰©æ•£æ¨¡å‹ç›¸å…³ç»„ä»¶ ===

class DyT(nn.Module):
    def __init__(self, num_features, alpha_init_value=0.5):
        super().__init__()
        self.alpha = nn.Parameter(torch.ones(1) * alpha_init_value)
        self.weight = nn.Parameter(torch.ones(num_features))
        self.bias = nn.Parameter(torch.zeros(num_features))

    def forward(self, x):
        x = torch.tanh(self.alpha * x)
        return x * self.weight + self.bias


# ä½¿ç”¨DyTçš„æ®‹å·®å—
class ResidualBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.layer = nn.Sequential(
            DyT(dim),  # ä½¿ç”¨DyTæ›¿ä»£LayerNorm
            nn.Linear(dim, dim),
            nn.GELU(),
            nn.Dropout(0.5)
        )

    def forward(self, x):
        return x + self.layer(x)  # æ®‹å·®è¿æ¥


class EnhancedDistancePredictor(nn.Module):
    """å¢å¼ºç‰ˆè·ç¦»é¢„æµ‹ç½‘ç»œ - æ¥å—è¿æ¥çš„èŠ‚ç‚¹ç‰¹å¾å¯¹"""

    def __init__(self, node_dim, hidden_dim=256, depth=1):
        super().__init__()
        # è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ç‰¹å¾è¿æ¥åçš„ç»´åº¦
        input_dim = node_dim * 2
        # åˆå§‹é™ç»´å±‚
        self.input_proj = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.5)
        )

        # ä¸­é—´å¤„ç†å±‚
        layers = []

        # ç¬¬ä¸€å±‚æ®‹å·®å— - ä½¿ç”¨DyTæ›¿ä»£LayerNorm
        layers.append(nn.Sequential(
            DyT(hidden_dim),  # ä½¿ç”¨DyTæ›¿ä»£LayerNorm
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.5)
        ))

        # å¤šä¸ªæ®‹å·®å—ï¼Œç»´åº¦ä¸ºhidden_dim
        for _ in range(depth):
            layers.append(ResidualBlock(hidden_dim))

        # æœ€ç»ˆé¢„æµ‹å±‚ - ä½¿ç”¨DyTæ›¿ä»£LayerNorm
        layers.append(nn.Sequential(
            DyT(hidden_dim),  # ä½¿ç”¨DyTæ›¿ä»£LayerNorm
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_dim // 2, 1)
        ))

        self.layers = nn.ModuleList(layers)
        # self.NodeFeatureSelfAttention = NodeFeatureSelfAttention(hidden_dim)

    def forward(self, x):
        # åˆå§‹æŠ•å½±
        x = self.input_proj(x)

        # åº”ç”¨ä¸­é—´å±‚
        x = self.layers[0](x)  # é™ç»´å±‚
        # x = self.NodeFeatureSelfAttention(x)
        # åº”ç”¨æ®‹å·®å—
        for i in range(1, len(self.layers) - 1):
            x = self.layers[i](x)

        # æœ€ç»ˆé¢„æµ‹
        x = self.layers[-1](x)

        return x.squeeze(-1)



class GaussianDiffusion:
    """å®ç°é«˜æ–¯æ‰©æ•£è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å‰å‘åŠ å™ªå’Œåå‘å»å™ª"""

    def __init__(self, num_timesteps=100, beta_start=1e-5, beta_end=0.001):
        self.num_timesteps = num_timesteps

        # ä½¿ç”¨æ›´ç¨³å®šçš„ä½™å¼¦è°ƒåº¦å‚æ•°
        # ä½¿ç”¨éçº¿æ€§å™ªå£°è°ƒåº¦ï¼Œå¯ä»¥æé«˜è®­ç»ƒç¨³å®šæ€§
        betas = torch.linspace(beta_start ** 0.5, beta_end ** 0.5,
                               num_timesteps) ** 2
        self.betas = betas

        # è®¡ç®—alphaå’Œç›¸å…³å‚æ•°
        self.alphas = 1. - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        self.alphas_cumprod_prev = torch.cat(
            [torch.tensor([1.0]), self.alphas_cumprod[:-1]])
        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(
            1. - self.alphas_cumprod)
        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)
        self.posterior_variance = self.betas * (
                1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)

        # è®¡ç®—æƒé‡ç³»æ•°ï¼Œè®©æŸå¤±æ›´åŠ å…³æ³¨é«˜å™ªå£°åŒºåŸŸ
        self.loss_weights = (self.alphas_cumprod / (
                1 - self.alphas_cumprod)) ** 0.5

    def q_sample(self, x_0, t, noise=None):
        """æ·»åŠ å™ªå£°çš„å‰å‘è¿‡ç¨‹"""
        if noise is None:
            noise = torch.randn_like(x_0)

        # è·å–å¯¹åº”æ—¶é—´æ­¥çš„å‚æ•°
        sqrt_alphas_cumprod_t = extract(self.sqrt_alphas_cumprod, t, x_0.shape)
        sqrt_one_minus_alphas_cumprod_t = extract(
            self.sqrt_one_minus_alphas_cumprod, t, x_0.shape)

        # åº”ç”¨æ‰©æ•£å…¬å¼: x_t = sqrt(Î±_t) * x_0 + sqrt(1-Î±_t) * Îµ
        return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise

    def p_losses(self, denoise_model, x_0, t, noise=None):
        """è®¡ç®—å»å™ªæ¨¡å‹çš„æŸå¤±å‡½æ•°"""
        if noise is None:
            noise = torch.randn_like(x_0)

        # æ·»åŠ å™ªå£°å¾—åˆ°x_t
        x_t = self.q_sample(x_0, t, noise)

        # ä½¿ç”¨å»å™ªæ¨¡å‹é¢„æµ‹å™ªå£°
        predicted_noise = denoise_model(x_t, t)

        # ä½¿ç”¨åŠ æƒMSEæŸå¤±ï¼Œæ›´åŠ å…³æ³¨é«˜å™ªå£°åŒºåŸŸ
        weights = extract(self.loss_weights, t, x_0.shape)
        loss = torch.mean(weights * (predicted_noise - noise) ** 2)

        return loss, predicted_noise

    @torch.no_grad()
    def p_sample(self, model, x_t, t):
        """å•æ­¥å»å™ªé‡‡æ ·"""
        # è·å–æ¨¡å‹å‚æ•°
        betas_t = extract(self.betas, t, x_t.shape)
        sqrt_one_minus_alphas_cumprod_t = extract(
            self.sqrt_one_minus_alphas_cumprod, t, x_t.shape)
        sqrt_recip_alphas_t = extract(self.sqrt_recip_alphas, t, x_t.shape)

        # é¢„æµ‹å™ªå£°
        predicted_noise = model(x_t, t)

        # è®¡ç®—å‡å€¼
        mean = sqrt_recip_alphas_t * (
                x_t - betas_t * predicted_noise / sqrt_one_minus_alphas_cumprod_t)
        #è®ºæ–‡ä¸­å…¬å¼4å‰åŠéƒ¨åˆ†
        # åªåœ¨t>0æ—¶æ·»åŠ å™ªå£°
        if t[0] > 0:
            noise = torch.randn_like(x_t)
            variance = extract(self.posterior_variance, t, x_t.shape)
            return mean + torch.sqrt(variance) * noise
        else:
            return mean

    @torch.no_grad()
    def denoise(self, model, x_t, t_start):
        """ä»æŒ‡å®šæ—¶é—´æ­¥å¼€å§‹å»å™ª"""
        x = x_t.clone()

        # ä»t_startå¼€å§‹é€æ­¥å»å™ª
        for t in reversed(range(t_start + 1)):
            t_batch = torch.full((x.shape[0],), t, device=x.device,
                                 dtype=torch.long)
            x = self.p_sample(model, x, t_batch)

        return x


# è¾…åŠ©å‡½æ•°ï¼šä»tensorä¸­æå–é€‚å½“å½¢çŠ¶çš„å…ƒç´ 
def extract(a, t, shape):
    """ä»tensor aä¸­æå–å¯¹åº”æ—¶é—´æ­¥tçš„å…ƒç´ ï¼Œå¹¶è°ƒæ•´ä¸ºé€‚å½“çš„å½¢çŠ¶"""
    batch_size = t.shape[0]
    out = a.gather(-1, t.cpu()).to(t.device)
    return out.reshape(batch_size, *((1,) * (len(shape) - 1)))


class SinusoidalPositionEmbeddings(nn.Module):
    """æ—¶é—´æ­¥çš„ä½ç½®ç¼–ç """

    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(
            torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings


class SelfAttention(nn.Module):
    """ä¿®æ”¹åçš„è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œå¯å¤„ç†2Dè¾“å…¥"""

    def __init__(self, dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.num_heads = num_heads
        self.scale = (dim // num_heads) ** -0.5

        self.qkv = nn.Linear(dim, dim * 3)
        self.proj = nn.Linear(dim, dim)
        self.dropout = nn.Dropout(dropout)
        self.norm = nn.LayerNorm(dim)

    def forward(self, x):
        # ä¿å­˜åŸå§‹è¾“å…¥ä»¥ä¾¿æœ€åæ·»åŠ æ®‹å·®è¿æ¥
        residual = x

        # åº”ç”¨å±‚å½’ä¸€åŒ–
        x = self.norm(x)

        # å¤„ç†2Dè¾“å…¥ [B, C] -> [B, 1, C]
        if len(x.shape) == 2:
            B, C = x.shape
            x = x.unsqueeze(1)  # æ·»åŠ åºåˆ—ç»´åº¦
            is_2d = True
        else:
            is_2d = False
            B, N, C = x.shape

        # è®¡ç®—æ³¨æ„åŠ›ï¼Œä»£ç ä¸åŸç‰ˆç›¸åŒ
        qkv = self.qkv(x).reshape(B, -1, 3, self.num_heads,
                                  C // self.num_heads).permute(2, 0, 3, 1, 4)
        q, k, v = qkv[0], qkv[1], qkv[2]

        attn = (q @ k.transpose(-2, -1)) * self.scale
        attn = attn.softmax(dim=-1)
        attn = self.dropout(attn)

        x = (attn @ v).transpose(1, 2).reshape(B, -1, C)
        x = self.proj(x)
        x = self.dropout(x)

        # å¦‚æœåŸå§‹è¾“å…¥æ˜¯2Dï¼Œæˆ‘ä»¬éœ€è¦å»æ‰åºåˆ—ç»´åº¦
        if is_2d:
            x = x.squeeze(1)

        return x + residual


class PreNormResidual(nn.Module):
    """æ”¹è¿›çš„æ®‹å·®å—ï¼Œä½¿ç”¨PreNormç»“æ„æé«˜è®­ç»ƒç¨³å®šæ€§"""

    def __init__(self, dim, dropout=0.1):
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.net = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.SiLU(),  # ä½¿ç”¨SiLU(Swish)æ¿€æ´»å‡½æ•°
            nn.Dropout(dropout),
            nn.Linear(dim * 4, dim),
            nn.Dropout(dropout)
        )

    def forward(self, x):
        return x + self.net(self.norm(x))


class DenoiseNet(nn.Module):
    """å¢å¼ºç‰ˆå»å™ªç½‘ç»œï¼Œæ·»åŠ è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œæ”¹è¿›çš„æ®‹å·®ç»“æ„"""

    def __init__(self, input_dim, time_dim=128, hidden_dim=256, depth=4,
                 dropout=0.1, use_attention=True):
        super().__init__()

        # 1. æ—¶é—´æ­¥åµŒå…¥ - ä½¿ç”¨æ›´æ·±çš„ç½‘ç»œ
        self.time_mlp = nn.Sequential(
            SinusoidalPositionEmbeddings(time_dim),
            nn.Linear(time_dim, hidden_dim),
            nn.SiLU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
        )

        # 2. è¾“å…¥å±‚ - æ·»åŠ æ‰¹å½’ä¸€åŒ–å’Œdropout
        self.input_layer = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.SiLU(),
            nn.LayerNorm(hidden_dim),
            nn.Dropout(dropout)
        )

        # 3. ä¸»å¹²ç½‘ç»œ - äº¤æ›¿ä½¿ç”¨æ³¨æ„åŠ›å’Œæ®‹å·®å—
        self.layers = nn.ModuleList([])
        for _ in range(depth):
            if use_attention:
                self.layers.append(nn.ModuleList([
                    PreNormResidual(hidden_dim, dropout=dropout),
                    SelfAttention(hidden_dim, dropout=dropout)
                ]))
            else:
                self.layers.append(nn.ModuleList([
                    PreNormResidual(hidden_dim, dropout=dropout),
                    PreNormResidual(hidden_dim, dropout=dropout)
                ]))

        # 4. æ—¶é—´åµŒå…¥ä¸ç‰¹å¾èåˆ - ä½¿ç”¨é—¨æ§æœºåˆ¶
        self.fusion = nn.Sequential(
            nn.LayerNorm(hidden_dim * 2),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.SiLU(),
            nn.Dropout(dropout),
            nn.LayerNorm(hidden_dim)
        )

        # 5. è¾“å‡ºå±‚ - æ·»åŠ æ®‹å·®è¿æ¥å’Œå¤šå±‚ç»“æ„
        self.output_block = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.SiLU(),
            nn.LayerNorm(hidden_dim // 2),
            nn.Linear(hidden_dim // 2, input_dim),
        )

        # ç›´æ¥è·³è·ƒè¿æ¥
        self.skip_connection = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, input_dim)
        ) if hidden_dim != input_dim else nn.Identity()

    def forward(self, x, timestep):
        # ç¡®ä¿æ—¶é—´æ­¥æ˜¯å¼ é‡
        if not isinstance(timestep, torch.Tensor):
            timestep = torch.tensor([timestep], device=x.device)

        # æ‰©å±•æ—¶é—´æ­¥ä»¥åŒ¹é…æ‰¹æ¬¡å¤§å°
        if timestep.shape[0] != x.shape[0]:
            timestep = timestep.expand(x.shape[0])

        # 1. è·å–æ—¶é—´åµŒå…¥
        t_emb = self.time_mlp(timestep)

        # 2. è¾“å…¥å±‚å¤„ç†
        h = self.input_layer(x)

        # ä¿å­˜åˆå§‹è¡¨ç¤ºç”¨äºæœ€ç»ˆè·³è·ƒè¿æ¥
        h_skip = h

        # 3. åº”ç”¨ä¸»å¹²ç½‘ç»œå±‚
        for attn_block, ff_block in self.layers:
            h = attn_block(h)
            # h = ff_block(h)

        # 4. ç‰¹å¾ä¸æ—¶é—´åµŒå…¥èåˆ
        B, N = h.shape
        h = h.view(B, N, 1)  # [B, N] -> [B, N, 1] ç”¨äºè‡ªæ³¨æ„åŠ›
        t_emb = t_emb.view(B, -1, 1).expand_as(h)  # è°ƒæ•´æ—¶é—´åµŒå…¥ç»´åº¦
        h_combined = torch.cat([h, t_emb], dim=1)  # åœ¨åºåˆ—ç»´åº¦ä¸Šè¿æ¥
        h_fused = self.fusion(h_combined.view(B, -1))  # å±•å¹³å¹¶èåˆ

        # 5. è¾“å‡ºé¢„æµ‹çš„å™ªå£° - æ·»åŠ æ®‹å·®è¿æ¥
        main_output = self.output_block(h_fused)
        skip_output = self.skip_connection(h_skip)

        # ç»„åˆä¸»è¾“å‡ºå’Œè·³è·ƒè¿æ¥
        return main_output + skip_output


class NodeDiffusionModel(nn.Module):
    """åŸºäºèŠ‚ç‚¹çš„æ‰©æ•£æ¨¡å‹ï¼Œåœ¨å•ä¸ªèŠ‚ç‚¹ç‰¹å¾ä¸Šæ‰§è¡Œæ‰©æ•£ï¼Œç„¶åè¿æ¥èŠ‚ç‚¹ç‰¹å¾æ¥é¢„æµ‹è·ç¦»"""

    def __init__(self, node_dim, diffusion_steps=100, beta_start=1e-4,
                 beta_end=0.02, hidden_dim=128, depth=2):
        super().__init__()

        # æ‰©æ•£è¿‡ç¨‹
        self.diffusion = GaussianDiffusion(
            num_timesteps=diffusion_steps,
            beta_start=beta_start,
            beta_end=beta_end
        )

        # å»å™ªç½‘ç»œ - å¤„ç†å•ä¸ªèŠ‚ç‚¹ç‰¹å¾
        self.denoise_net = DenoiseNet(
            input_dim=node_dim,
            hidden_dim=hidden_dim
        )

        # è·ç¦»é¢„æµ‹ç½‘ç»œ - å¤„ç†è¿æ¥çš„èŠ‚ç‚¹ç‰¹å¾å¯¹
        self.distance_predictor = EnhancedDistancePredictor(
            node_dim=node_dim,
            hidden_dim=hidden_dim,
            depth=depth
        )

        self.node_dim = node_dim
        self.diffusion_steps = diffusion_steps

    def forward_diffusion(self, x_0, t):
        """å‰å‘æ‰©æ•£ï¼šæ·»åŠ å™ªå£°åˆ°èŠ‚ç‚¹ç‰¹å¾"""
        return self.diffusion.q_sample(x_0, t)

    def denoise(self, x_t, t_start):
        """ä»t_startæ­¥å¼€å§‹å»å™ªèŠ‚ç‚¹ç‰¹å¾"""
        return self.diffusion.denoise(self.denoise_net, x_t, t_start)

    def predict_distance(self, src_features, dst_features):
        """é¢„æµ‹ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è·ç¦»ï¼Œæ¥å—ä¸¤ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾"""
        # è¿æ¥æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹çš„ç‰¹å¾
        pair_features = torch.cat([src_features, dst_features], dim=1)
        return self.distance_predictor(pair_features)

    def get_diffusion_loss(self, x_0, t):
        """è®¡ç®—æ‰©æ•£æ¨¡å‹æŸå¤±ï¼ˆä»…å¯¹èŠ‚ç‚¹ç‰¹å¾ï¼‰"""
        return self.diffusion.p_losses(self.denoise_net, x_0, t)

    def get_prediction_loss(self, src_features, dst_features, true_distances):
        """è®¡ç®—è·ç¦»é¢„æµ‹æŸå¤±"""
        predictions = self.predict_distance(src_features, dst_features)
        return nn.MSELoss()(predictions, true_distances), predictions


def train_diffusion_model(model, data, device, optimizer,
                          batch_size, diffusion_steps, num_epochs,
                          scheduler=None):
    """è®­ç»ƒæ‰©æ•£æ¨¡å‹ - ä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹æ•°æ®"""
    print("===== Phase 1: Training Diffusion Model =====")
    best_loss = float('inf')

    # è·å–æ‰€æœ‰èŠ‚ç‚¹çš„ç‰¹å¾
    all_nodes = torch.arange(data.x.shape[0])
    node_features = data.x.to(device)
    print(f"Training diffusion model on {len(all_nodes)} nodes (ALL nodes)")

    for epoch in range(num_epochs):
        model.train()
        epoch_losses = []

        # æ‰“ä¹±æ•°æ®
        perm = torch.randperm(node_features.shape[0], device=device)
        shuffled_features = node_features[perm]

        # æ‰¹é‡è®­ç»ƒèŠ‚ç‚¹ç‰¹å¾æ‰©æ•£
        for i in range(0, shuffled_features.shape[0], batch_size):
            batch_features = shuffled_features[i:i + batch_size]
            if len(batch_features) == 0:
                continue

            # éšæœºé€‰æ‹©æ—¶é—´æ­¥
            t = torch.randint(0, diffusion_steps, (batch_features.shape[0],),
                              device=device)

            # è®¡ç®—æ‰©æ•£æŸå¤±
            loss, _ = model.get_diffusion_loss(batch_features, t)

            # ä¼˜åŒ–æ­¥éª¤
            optimizer.zero_grad()
            loss.backward()

            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()
            epoch_losses.append(loss.item())

        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler:
            scheduler.step()

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = np.mean(epoch_losses) if epoch_losses else float('inf')

        # æ¯1ä¸ªepochæŠ¥å‘Šä¸€æ¬¡
        if epoch % 1 == 0:
            print(f"Epoch {epoch}: Diffusion Loss = {avg_loss:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_loss < best_loss:
                best_loss = avg_loss
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': best_loss,
                }, "best_diffusion_model.pt")
                print(f"  New best model saved! Loss: {best_loss:.6f}")

    print(f"Diffusion model training completed. Best loss: {best_loss:.6f}")
    return model


def generate_denoised_node_features(model, data, device, diffusion_steps=50,
                                    batch_size=128):
    """ä¸ºæ‰€æœ‰èŠ‚ç‚¹ç”Ÿæˆå»å™ªç‰¹å¾"""
    model.eval()

    # è·å–æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾
    all_nodes = torch.arange(data.x.shape[0])
    all_features = data.x.to(device)

    # ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆå»å™ªç‰¹å¾
    denoised_features = []

    with torch.no_grad():
        for i in range(0, all_features.shape[0], batch_size):
            batch_features = all_features[i:i + batch_size]
            if len(batch_features) == 0:
                continue

            # æ·»åŠ å™ªå£°
            t = torch.full((batch_features.shape[0],), diffusion_steps,
                           device=device, dtype=torch.long)
            noisy_features = model.forward_diffusion(batch_features, t)

            # å»å™ª
            batch_denoised = model.denoise(noisy_features, diffusion_steps)
            denoised_features.append(batch_denoised)

    # åˆå¹¶æ‰€æœ‰å»å™ªç‰¹å¾
    denoised_features = torch.cat(denoised_features, dim=0)

    # åˆ›å»ºèŠ‚ç‚¹ç´¢å¼•åˆ°å»å™ªç‰¹å¾çš„æ˜ å°„
    node_to_feature = {}
    for i, node_idx in enumerate(all_nodes.cpu().numpy()):
        node_to_feature[node_idx.item()] = denoised_features[i]

    return node_to_feature, denoised_features


def create_combined_training_data(data, denoised_features, train_indices,
                                  test_indices, device):
    """åˆ›å»ºæ‰©å±•çš„è®­ç»ƒæ•°æ®ï¼Œå»å™ªæ•°æ®åªç”¨äºè®­ç»ƒä¸ç”¨äºæµ‹è¯•"""
    num_nodes = data.x.shape[0]

    # è·å–åŸå§‹è®­ç»ƒå’Œæµ‹è¯•è¾¹
    original_src_nodes_train, original_dst_nodes_train = data.edge_index[:,
                                                         train_indices]
    original_true_distances_train = data.edge_attr[train_indices].to(device)

    original_src_nodes_test, original_dst_nodes_test = data.edge_index[:,
                                                       test_indices]
    original_true_distances_test = data.edge_attr[test_indices].to(device)

    # åˆ›å»ºæ‰©æ•£èŠ‚ç‚¹çš„åç§»ç´¢å¼•
    diffusion_offset = num_nodes

    # åˆ›å»ºç»„åˆè®­ç»ƒæ•°æ®
    combined_train_data = []

    # 1. åŸå§‹èŠ‚ç‚¹ä¹‹é—´çš„è®­ç»ƒè¾¹
    for i in range(len(train_indices)):
        src = original_src_nodes_train[i].item()
        dst = original_dst_nodes_train[i].item()
        dist = original_true_distances_train[i].item()
        combined_train_data.append((src, dst, dist, "original-original"))

    # 2. æ‰©æ•£èŠ‚ç‚¹ä¹‹é—´çš„è®­ç»ƒè¾¹ï¼ˆä¸åŸå§‹è®­ç»ƒè¾¹å¯¹åº”ï¼‰
    for i in range(len(train_indices)):
        src = original_src_nodes_train[i].item() + diffusion_offset
        dst = original_dst_nodes_train[i].item() + diffusion_offset
        dist = original_true_distances_train[i].item()  # ä¿æŒç›¸åŒçš„æŠ—åŸè·ç¦»
        combined_train_data.append((src, dst, dist, "diffusion-diffusion"))

    # åˆ›å»ºæµ‹è¯•æ•°æ® - åªåŒ…å«åŸå§‹èŠ‚ç‚¹
    test_data = []

    # åªä½¿ç”¨åŸå§‹èŠ‚ç‚¹çš„æµ‹è¯•è¾¹
    for i in range(len(test_indices)):
        src = original_src_nodes_test[i].item()
        dst = original_dst_nodes_test[i].item()
        dist = original_true_distances_test[i].item()
        test_data.append((src, dst, dist, "original-original"))

    return combined_train_data, test_data, diffusion_offset


def create_combined_feature_mapping(data, denoised_features, diffusion_offset,
                                    device):
    """åˆ›å»ºèŠ‚ç‚¹åˆ°ç‰¹å¾çš„æ˜ å°„ï¼ŒåŒ…å«åŸå§‹èŠ‚ç‚¹å’Œæ‰©æ•£èŠ‚ç‚¹"""
    node_to_feature = {}

    # 1. æ·»åŠ åŸå§‹èŠ‚ç‚¹ç‰¹å¾
    for node_idx in range(data.x.shape[0]):
        node_to_feature[node_idx] = data.x[node_idx].to(device)

    # 2. æ·»åŠ æ‰©æ•£èŠ‚ç‚¹ç‰¹å¾
    for node_idx in range(data.x.shape[0]):
        diffusion_node_idx = node_idx + diffusion_offset
        node_to_feature[diffusion_node_idx] = denoised_features[node_idx].to(
            device)

    return node_to_feature


def evaluate_model_with_combined_data(model, combined_test_data,
                                      node_to_feature, device, batch_size=128,
                                      plot_correlation=False, save_path=None):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆä½¿ç”¨ç»„åˆæ•°æ®ï¼‰"""
    model.eval()

    if not combined_test_data:
        return float('inf')

    # è¯„ä¼°æ¨¡å‹
    all_predictions = []
    all_true_distances = []

    with torch.no_grad():
        for i in range(0, len(combined_test_data), batch_size):
            batch_data = combined_test_data[i:i + batch_size]
            if len(batch_data) == 0:
                continue

            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
            src_list, dst_list, dist_list, _ = zip(*batch_data)

            # è·å–èŠ‚ç‚¹ç‰¹å¾
            src_features = torch.stack(
                [node_to_feature[src] for src in src_list])
            dst_features = torch.stack(
                [node_to_feature[dst] for dst in dst_list])

            # è·å–çœŸå®è·ç¦»
            batch_true_distances = torch.tensor(dist_list, device=device,
                                                dtype=torch.float)

            # é¢„æµ‹è·ç¦»
            predictions = model.predict_distance(src_features, dst_features)

            all_predictions.append(predictions)
            all_true_distances.append(batch_true_distances)

    # åˆå¹¶æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®è·ç¦»
    all_predictions = torch.cat(all_predictions, dim=0)
    all_true_distances = torch.cat(all_true_distances, dim=0)

    # è®¡ç®—MSE
    mse = nn.MSELoss()(all_predictions, all_true_distances).item()
    # è½¬æ¢ä¸ºNumPyæ•°ç»„è¿›è¡Œè¿›ä¸€æ­¥åˆ†æ
    pred_np = all_predictions.cpu().numpy()
    true_np = all_true_distances.cpu().numpy()
    mae = mean_absolute_error(true_np, pred_np)
    # mse = mean_squared_error(true_np, pred_np)
    r2 = r2_score(true_np, pred_np)
    # if plot_correlation:


    return mae, mse, r2
    # return mse


def train_distance_predictor_with_combined_data(model, combined_train_data,
                                                test_data,
                                                node_to_feature, device,
                                                optimizer,
                                                batch_size, num_epochs,
                                                scheduler=None):
    """ä½¿ç”¨ç»„åˆæ•°æ®è®­ç»ƒè·ç¦»é¢„æµ‹å™¨ï¼Œä½†ä»…ä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œæµ‹è¯•è¯„ä¼°"""
    print("===== Phase 2: Training Distance Predictor with Combined Data =====")
    best_train_loss = float('inf')
    best_test_loss = float('inf')

    print(
        f"Training distance predictor on {len(combined_train_data)} edges (including original and diffusion)")
    print(f"Testing only on {len(test_data)} original edges")

    for epoch in range(num_epochs):
        # ===== è®­ç»ƒé˜¶æ®µ =====
        model.train()
        epoch_losses = []

        # æ‰“ä¹±æ•°æ®
        np.random.shuffle(combined_train_data)

        # æ‰¹é‡è®­ç»ƒ
        for i in range(0, len(combined_train_data), batch_size):
            batch_data = combined_train_data[i:i + batch_size]
            if len(batch_data) == 0:
                continue

            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
            src_list, dst_list, dist_list, _ = zip(*batch_data)

            # è·å–èŠ‚ç‚¹ç‰¹å¾
            src_features = torch.stack(
                [node_to_feature[src] for src in src_list])
            dst_features = torch.stack(
                [node_to_feature[dst] for dst in dst_list])

            # è·å–çœŸå®è·ç¦»
            true_distances = torch.tensor(dist_list, device=device,
                                          dtype=torch.float)

            # è®¡ç®—é¢„æµ‹æŸå¤±
            loss, _ = model.get_prediction_loss(src_features, dst_features,
                                                true_distances)

            # ä¼˜åŒ–æ­¥éª¤
            optimizer.zero_grad()
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()
            epoch_losses.append(loss.item())

        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler:
            scheduler.step()

        # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
        avg_train_loss = np.mean(epoch_losses) if epoch_losses else float('inf')

        # æ‰“å°å½“å‰epochçš„è®­ç»ƒæŸå¤±
        if epoch % 5 != 0:
            print(f"Epoch {epoch}: Train Loss = {avg_train_loss:.6f}")

        # ===== æ¯5ä¸ªepochæ‰§è¡Œæµ‹è¯•é˜¶æ®µ =====
        if epoch % 2 == 0:
            # è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ - ä»…ä½¿ç”¨åŸå§‹æ•°æ®
            test_mae, test_loss, test_r2 = evaluate_model_with_combined_data(
                model=model,
                combined_test_data=test_data,  # åªåŒ…å«åŸå§‹æ•°æ®çš„æµ‹è¯•é›†
                node_to_feature=node_to_feature,
                device=device,
                batch_size=batch_size
            )

            # æ‰“å°å½“å‰epochçš„è®­ç»ƒå’Œæµ‹è¯•æŸå¤±
            print(
                f"Epoch {epoch}: Train Loss = {avg_train_loss:.6f}, Test Loss = {test_loss:.6f}")
            # åªè®°å½•æœ€ä½³æµ‹è¯•æŸå¤±ï¼Œä½†ä¸ä¿å­˜è¯¥æ¨¡å‹
            if test_loss < best_test_loss:
                best_test_loss = test_loss
                best_test_mae = test_mae  # ä¿å­˜ç›¸åº”çš„MAEå€¼
                best_test_r2 = test_r2  # ä¿å­˜ç›¸åº”çš„R2å€¼
                print(
                    f"  New best test loss: {best_test_loss:.6f}, Test MAE: {test_mae:.6f}, Test RÂ²: {test_r2:.6f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºè®­ç»ƒé›†æ€§èƒ½ï¼‰- æ¯ä¸ªepochéƒ½æ£€æŸ¥
        if avg_train_loss < best_train_loss:
            best_train_loss = avg_train_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': avg_train_loss,
                'test_loss': test_loss if epoch % 5 == 0 else None,
            }, "best_distance_predictor_by_train.pt")
            print(
                f"  New best model by train saved! Train Loss: {best_train_loss:.6f}")

    print(f"Distance predictor training completed.")
    print(
        f"Best train loss: {best_train_loss:.6f}, Best test loss: {best_test_loss:.6f}, Best test MAE: {best_test_mae:.6f}, Best test RÂ²: {best_test_r2:.6f}")
    return model


# ä¸»è®­ç»ƒé€»è¾‘
if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ï¼Œæé«˜å¯é‡å¤æ€§
    torch.manual_seed(42)
    np.random.seed(42)

    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # åŠ è½½æ•°æ®
    # gData = graphDataset("test newnature566H3N2")
    # gData = graphDataset("newnature566H1N1")
    # gData = graphDataset("nature566H1N1")
    gData = graphDataset("nature566H3N2")
    # gData = graphDataset("nature585BVictoria")
    # gData = graphDataset("nature585BYamagata")
    # gData = graphDataset("nature566H1N1ä¸å¯¹ç§°")
    # gData = graphDataset("nature566H3N2ä¸å¯¹ç§°")
    # gData = graphDataset("nature585BVictoriaä¸å¯¹ç§°")
    # gData = graphDataset("nature585BYamagataä¸å¯¹ç§°")
    # print(f"ä½¿ç”¨æ•°æ®é›†:nature585BYamagataä¸å¯¹ç§°")
    data = gData.data.to(device)
    num_edges = data.edge_index.shape[1]

    # è·å–èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
    node_dim = data.x.shape[1]
    print(f"Node feature dimension: {node_dim}")

    # å›¾å¯¹æ¯”å­¦ä¹ éƒ¨åˆ†
    encoder_learning_rate = 0.0008
    weight_decay_encoder = 0.0005
    base_model = GATConv
    num_layers = 2
    tau = 0.3
    num_hidden = 128
    num_proj_hidden = 64

    # åˆå§‹åŒ–ç¼–ç å™¨
    encoder = Encoder(node_dim, num_hidden, F.relu, base_model=base_model,
                      k=num_layers).to(device)
    encoder_model = GATModel(encoder, num_hidden, num_proj_hidden, node_dim,
                             tau).to(device)

    # å®šä¹‰ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    encoder_optimizer = torch.optim.Adam(encoder_model.parameters(),
                                         lr=encoder_learning_rate,
                                         weight_decay=weight_decay_encoder)
    encoder_scheduler = torch.optim.lr_scheduler.StepLR(encoder_optimizer,
                                                        step_size=200,
                                                        gamma=0.9)
    encoderbest_loss = float('inf')  # åˆå§‹åŒ–æœ€ä½³æŸå¤±ä¸ºæ— ç©·å¤§
    encoderbest_epoch = 0  # è®°å½•æœ€ä½³æŸå¤±çš„è½®æ¬¡
    # å›¾å¯¹æ¯”å­¦ä¹ è®­ç»ƒ
    start = t()
    prev = start
    for epoch in range(1, 600):
        encoder_loss = encoder_train(encoder_model, data.x, data.edge_index)
        now = t()
        print(
            f'(T) | Epoch={epoch:03d}, encoderContrastive_loss={encoder_loss:.4f}, '
            f'this epoch {now - prev:.4f}, total {now - start:.4f}')
        prev = now

    print("=== Encoder Training Completed ===")

    # ç”ŸæˆèŠ‚ç‚¹åµŒå…¥å‘é‡
    encoder_model.eval()
    # torch.save(encoder_model.state_dict(), 'best_encoderH3N2_model.pth')
    # encoder_model.load_state_dict(torch.load('encoderH3N2_model.pth'))
    with torch.no_grad():
        z1 = encoder_model(data.x, data.edge_index)

    print("Shape of node embeddings:", z1.shape)
    data.x = z1  # ä½¿ç”¨ç”Ÿæˆçš„åµŒå…¥å‘é‡æ›¿æ¢åŸå§‹ç‰¹å¾

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    node_dim = data.x.shape[1]
    indices = torch.randperm(num_edges, device=device)
    train_ratio = 0.8
    split = int(train_ratio * num_edges)
    train_idx = indices[:split]
    test_idx = indices[split:]

    print(
        f"Training on {len(train_idx)} edges, testing on {len(test_idx)} edges")

    # æ¨¡å‹å‚æ•°
    diffusion_steps = 100
    hidden_dim = 512
    batch_size = 512

    # åˆå§‹åŒ–èŠ‚ç‚¹çº§åˆ«çš„æ‰©æ•£æ¨¡å‹
    model = NodeDiffusionModel(
        node_dim=node_dim,
        diffusion_steps=diffusion_steps,
        beta_start=1e-6,
        beta_end=0.000001,#åŸæ¥beta_end=0.0001,
        hidden_dim=hidden_dim
    ).to(device)

    # è®­ç»ƒå‚æ•°
    diffusion_epochs = 700#åŸæ¥1500
    predictor_epochs = 500#

    print(
        "Starting enhanced training process with original and diffused nodes...")

    # é˜¶æ®µ1ï¼šè®­ç»ƒæ‰©æ•£æ¨¡å‹
    diffusion_optimizer = optim.Adam(
        model.denoise_net.parameters(),
        lr=2e-4,
        weight_decay=1e-5
    )
    diffusion_scheduler = CosineAnnealingLR(diffusion_optimizer,
                                            T_max=diffusion_epochs,
                                            eta_min=1e-6)

    # è®­ç»ƒæ‰©æ•£æ¨¡å‹ - ä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹
    model = train_diffusion_model(
        model=model,
        data=data,
        device=device,
        optimizer=diffusion_optimizer,
        batch_size=batch_size,
        diffusion_steps=diffusion_steps,
        num_epochs=diffusion_epochs,
        scheduler=diffusion_scheduler
    )
    checkpoint = torch.load("best_diffusion_model.pt")
    model.load_state_dict(checkpoint['model_state_dict'])
    # ä¸ºæ‰€æœ‰èŠ‚ç‚¹ç”Ÿæˆå»å™ªç‰¹å¾
    print("Generating denoised node features...")
    data_x_backup = data.x.clone().detach()
    node_to_feature_original, denoised_features = generate_denoised_node_features(
        model=model,
        data=data,
        device=device,
        diffusion_steps=diffusion_steps // 10,
        batch_size=batch_size
    )


    original_features_np = data_x_backup.cpu().numpy()
    denoised_features_np = denoised_features.cpu().detach().numpy()

    # æ‰§è¡Œt-SNEé™ç»´
    print("æ­£åœ¨æ‰§è¡Œt-SNEé™ç»´...")
    tsne_original = TSNE(n_components=2, perplexity=12, method='exact',
                         init='pca', n_iter=2000, early_exaggeration=11,
                         random_state=42)
    original_2d = tsne_original.fit_transform(original_features_np)

    tsne_denoised = TSNE(n_components=2, perplexity=12, method='exact',
                         init='pca', n_iter=2000, early_exaggeration=11,
                         random_state=42)
    denoised_2d = tsne_denoised.fit_transform(denoised_features_np)

    # åªå¯¹åŸå§‹ç‰¹å¾æ‰§è¡ŒK-meansèšç±»ï¼Œç”¨äºç¡®å®šé¢œè‰²
    print("æ­£åœ¨æ‰§è¡ŒK-meansèšç±»...")
    num_clusters = 7
    kmeans_original = KMeans(n_clusters=num_clusters, random_state=42)
    original_clusters = kmeans_original.fit_predict(original_2d)

    # ä¸ºäº†è®¡ç®—èšç±»ç›¸ä¼¼åº¦ï¼Œæˆ‘ä»¬ä»ç„¶å¯¹å»å™ªç‰¹å¾è¿›è¡Œèšç±»ï¼Œä½†åªç”¨äºè®¡ç®—ç›¸ä¼¼åº¦ï¼Œä¸ç”¨äºç»˜å›¾ç€è‰²
    kmeans_denoised = KMeans(n_clusters=num_clusters, random_state=42)
    denoised_clusters = kmeans_denoised.fit_predict(denoised_2d)

    # è®¡ç®—èšç±»ç›¸ä¼¼åº¦æŒ‡æ ‡
    from sklearn.metrics import adjusted_rand_score

    cluster_similarity = adjusted_rand_score(original_clusters,
                                             denoised_clusters)
    print(f"èšç±»ç›¸ä¼¼åº¦ (ARI): {cluster_similarity:.3f}")


    try:
        virus_names = data.virus_names  # æˆ–è€… data['virus_names'] æˆ–è€… data.nameç­‰
        print(f"âœ… æˆåŠŸè·å– {len(virus_names)} ä¸ªæ¯’æ ªåç§°")
    except:
        print("âš ï¸  æ— æ³•ä»dataå¯¹è±¡è·å–virus_namesï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ...")

        # æ–¹æ³•2ï¼šå¦‚æœæ‚¨æœ‰å…¶ä»–åŒ…å«æ¯’æ ªåç§°çš„å˜é‡
        try:
            virus_names = [f"Strain_{i}" for i in
                           range(len(original_2d))]  # ç”Ÿæˆé€šç”¨åç§°
            print(f"âœ… ç”Ÿæˆäº† {len(virus_names)} ä¸ªé€šç”¨æ¯’æ ªåç§°")
        except:
            # æ–¹æ³•3ï¼šåŸºäºç´¢å¼•ç”Ÿæˆåç§°
            virus_names = [f"Sample_{i + 1}" for i in range(len(original_2d))]
            print(f"âœ… åŸºäºç´¢å¼•ç”Ÿæˆäº† {len(virus_names)} ä¸ªæ ·æœ¬åç§°")


    def create_interactive_tsne_visualization(original_2d, denoised_2d,
                                              original_clusters, virus_names,
                                              num_clusters=6):
        """
        åˆ›å»ºäº¤äº’å¼t-SNEå¯è§†åŒ–
        """
        # ç–«è‹—æ ªåˆ—è¡¨
        special_viruses = [
            'A/Bangkok/1/1979', 'A/Beijing/353/1989', 'A/Brisbane/10/2007',
            'A/California/7/2004', 'A/Cambodia/e0826360/2020',
            'A/Croatia/10136RV/2023',
            'A/Darwin/6/2021', 'A/Darwin/9/2021', 'A/Fujian/411/2002',
            'A/Hong Kong/2671/2019', 'A/Hong Kong/45/2019',
            'A/Hong Kong/4801/2014',
            'A/Johannesburg/33/1994', 'A/Kansas/14/2017',
            'A/Leningrad/360/1986',
            'A/Massachusetts/18/2022', 'A/Moscow/10/99', 'A/Perth/16/2009',
            'A/Philippines/2/1982', 'A/Shangdong/9/1993', 'A/Sichuan/2/1987',
            'A/Singapore/INFIMH-16-0019/2016', 'A/South Australia/34/2019',
            'A/Switzerland/8060/2017', 'A/Switzerland/9715293/2013',
            'A/Sydney/5/1997',
            'A/Texas/50/2012', 'A/Thailand/8/2022', 'A/Victoria/361/2011',
            'A/Wellington/1/2004', 'A/Wisconsin/67/2005', 'A/Wuhan/359/1995'
        ]
        # special_viruses = [
        #     'A/Victoria/4897/2022', 'A/Wisconsin/67/2022', 'A/Sydney/5/2021',
        #     'A/Victoria/2570/2019', 'A/Wisconsin/588/2019',
        #     'A/Guangdong-Maonan/SWL1536/2019', 'A/Hawaii/70/2019',
        #     'A/Brisbane/02/2018', 'A/Michigan/45/2015', 'A/California/7/2009',
        #     'A/Brisbane/59/2007', 'A/Solomon Islands/3/2006',
        #     'A/New Caledonia/20/99', 'A/Beijing/262/95', 'A/Bayern/7/95',
        #     'A/Singapore/6/86', 'A/Chile/1/83', 'A/Brazil/11/78'
        # ]#h1n1ç–«è‹—æ ª

        # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
                  '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']

        # ğŸ”§ æ¤­åœ†å¤§å°è°ƒæ•´ - è¿™é‡Œæ§åˆ¶æ¤­åœ†çš„æ•´ä½“å¤§å°
        # å¦‚æœè¦æ¤­åœ†æ›´å¤§ï¼ŒåŒæ—¶å¢åŠ ä¸¤ä¸ªå€¼ï¼›è¦æ›´å°ï¼ŒåŒæ—¶å‡å°‘ä¸¤ä¸ªå€¼
        ELLIPSE_WIDTH = 2.4  # æ¤­åœ†å®½åº¦ï¼ˆæ•´ä½“å¤§å°ï¼‰
        ELLIPSE_HEIGHT = 1.8  # æ¤­åœ†é«˜åº¦ï¼ˆæ•´ä½“å¤§å°ï¼‰

        print(f"ğŸ”¸ æ¤­åœ†è®¾ç½®: å®½åº¦={ELLIPSE_WIDTH}, é«˜åº¦={ELLIPSE_HEIGHT}")
        print(f"ğŸ’¡ è¦è°ƒæ•´æ¤­åœ†å¤§å°ï¼Œä¿®æ”¹ ELLIPSE_WIDTH å’Œ ELLIPSE_HEIGHT çš„å€¼")
        print(f"   - æ›´å¤§æ¤­åœ†: 1.5, 1.2")
        print(f"   - æ›´å°æ¤­åœ†: 0.6, 0.5")
        print(f"   - æ¥è¿‘åœ†å½¢: 1.0, 1.0")

        # åˆ›å»ºå›¾å½¢
        fig = go.Figure()

        # æ·»åŠ åŸå§‹ç‰¹å¾ç‚¹ï¼ˆåœ†å½¢ï¼‰
        for i in range(num_clusters):
            mask = original_clusters == i
            if np.any(mask):
                # ä¸ºè¯¥èšç±»çš„æ¯ä¸ªç‚¹åˆ›å»ºhoveræ–‡æœ¬
                cluster_virus_names = []
                cluster_vaccine_info = []
                for j in range(len(virus_names)):
                    if mask[j]:
                        virus_name = virus_names[j]
                        # ğŸ†• æ£€æŸ¥æ˜¯å¦ä¸ºç–«è‹—æ ª
                        is_vaccine = "æ˜¯" if virus_name in special_viruses else "å¦"
                        cluster_virus_names.append(virus_name)
                        cluster_vaccine_info.append(is_vaccine)

                fig.add_trace(go.Scatter(
                    x=original_2d[mask, 0],
                    y=original_2d[mask, 1],
                    mode='markers',
                    marker=dict(
                        size=15,
                        color=colors[i % len(colors)],
                        opacity=0.7,
                        symbol='circle',
                        line=dict(width=1, color='white')
                    ),
                    text=cluster_virus_names,
                    hovertemplate='<b>%{text}</b><br>' +
                                  'Original Features<br>' +
                                  'Cluster: ' + str(i) + '<br>' +
                                  'Vaccine Strain: %{customdata}<br>' +
                                  '<extra></extra>',
                    customdata=cluster_vaccine_info,
                    name=f'Original Cluster {i}',
                    showlegend=False
                ))

        # ğŸ”„ ä¿®æ”¹ï¼šå»å™ªç‰¹å¾ä½¿ç”¨è‡ªå®šä¹‰æ¤­åœ†
        ellipse_shapes = []  # ç”¨äºæ”¶é›†æ¤­åœ†shapes

        for i in range(num_clusters):
            mask = original_clusters == i
            if np.any(mask):
                # ä¸ºè¯¥èšç±»çš„æ¯ä¸ªç‚¹åˆ›å»ºhoveræ–‡æœ¬
                cluster_virus_names = []
                cluster_vaccine_info = []
                for j in range(len(virus_names)):
                    if mask[j]:
                        virus_name = virus_names[j]
                        is_vaccine = "æ˜¯" if virus_name in special_viruses else "å¦"
                        cluster_virus_names.append(virus_name)
                        cluster_vaccine_info.append(is_vaccine)

                # æ·»åŠ é€æ˜ç‚¹ï¼ˆåªç”¨äºhoveräº¤äº’ï¼‰
                fig.add_trace(go.Scatter(
                    x=denoised_2d[mask, 0],
                    y=denoised_2d[mask, 1],
                    mode='markers',
                    marker=dict(
                        size=1,
                        color=colors[i % len(colors)],
                        opacity=0
                    ),
                    text=cluster_virus_names,
                    hovertemplate='<b>%{text}</b><br>' +
                                  'Denoised Features<br>' +
                                  'Cluster: ' + str(i) + '<br>' +
                                  'Vaccine Strain: %{customdata}<br>' +
                                  '<extra></extra>',
                    customdata=cluster_vaccine_info,
                    name=f'Denoised Cluster {i}',
                    showlegend=False
                ))

                # ä¸ºè¯¥èšç±»çš„æ¯ä¸ªç‚¹åˆ›å»ºæ¤­åœ†
                cluster_indices = np.where(mask)[0]
                for idx in cluster_indices:
                    x_center = denoised_2d[idx, 0]
                    y_center = denoised_2d[idx, 1]

                    ellipse_shapes.append(
                        dict(
                            type="circle",
                            xref="x", yref="y",
                            x0=x_center - ELLIPSE_WIDTH / 2,  # å·¦è¾¹ç•Œ
                            y0=y_center - ELLIPSE_HEIGHT / 2,  # ä¸‹è¾¹ç•Œ
                            x1=x_center + ELLIPSE_WIDTH / 2,  # å³è¾¹ç•Œ
                            y1=y_center + ELLIPSE_HEIGHT / 2,  # ä¸Šè¾¹ç•Œ
                            fillcolor=colors[i % len(colors)],
                            opacity=0.9,
                            line=dict(color="black", width=1)
                        )
                    )

        print(f"âœ… åˆ›å»ºäº† {len(ellipse_shapes)} ä¸ªæ¤­åœ†")

        # ğŸ¨ ç®€åŒ–å›¾ä¾‹ - ä½¿ç”¨æ ‡å‡†Plotlyå›¾ä¾‹å’Œæ¸…æ™°çš„æ–‡æœ¬æ ‡è¯†
        fig.add_trace(go.Scatter(
            x=[None], y=[None],
            mode='markers',
            marker=dict(
                size=0,  # éšè—marker
                opacity=0  # å®Œå…¨é€æ˜
            ),
            name='â— Original Features',
            showlegend=True
        ))

        fig.add_trace(go.Scatter(
            x=[None], y=[None],
            mode='markers',
            marker=dict(
                size=0,  # éšè—marker
                opacity=0  # å®Œå…¨é€æ˜
            ),
            name='â¬¬ Denoised Features',
            showlegend=True
        ))



        # è®¾ç½®å¸ƒå±€
        fig.update_layout(
            title=dict(
                text=f'H3N2 - Interactive t-SNE Visualization',
                x=0.5,
                font=dict(size=16)
            ),
            xaxis=dict(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray',
                showticklabels=False,
                showline=False,
                zeroline=False,
                scaleanchor="y",
                scaleratio=1
            ),
            yaxis=dict(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray',
                showticklabels=False,
                showline=False,
                zeroline=False
            ),
            plot_bgcolor='white',
            width=800,
            height=800,
            shapes=ellipse_shapes,  # åŒ…å«æ‰€æœ‰æ¤­åœ†ï¼ˆæ•°æ®+å›¾ä¾‹ç¤ºä¾‹ï¼‰
            legend=dict(
                yanchor="top",
                y=0.99,
                xanchor="right",
                x=0.99,
                bgcolor="rgba(255,255,255,0.8)"
            ),
            hovermode='closest'
        )

        return fig


    # ========== ä½¿ç”¨ä¿®æ­£åçš„å‡½æ•° ==========
    print("æ­£åœ¨åˆ›å»ºä¿®æ­£çš„äº¤äº’å¼t-SNEå¯è§†åŒ–...")

    # è°ƒç”¨å‡½æ•°åˆ›å»ºäº¤äº’å¼å›¾å½¢
    interactive_fig = create_interactive_tsne_visualization(
        original_2d=original_2d,
        denoised_2d=denoised_2d,
        original_clusters=original_clusters,
        virus_names=virus_names,
        num_clusters=num_clusters
    )

    # æ˜¾ç¤ºäº¤äº’å¼å›¾å½¢
    interactive_fig.show()

    # ä¿å­˜ä¸ºHTMLæ–‡ä»¶
    interactive_fig.write_html("H3N2_interactive_tsne_visualization.html")


    # ========== ğŸ†• ç–«è‹—æ ªç»Ÿè®¡ä¿¡æ¯ ==========
    # special_viruses = [
    #     'A/Bangkok/1/1979', 'A/Beijing/353/1989', 'A/Brisbane/10/2007',
    #     'A/California/7/2004', 'A/Cambodia/e0826360/2020',
    #     'A/Croatia/10136RV/2023',
    #     'A/Darwin/6/2021', 'A/Darwin/9/2021', 'A/Fujian/411/2002',
    #     'A/Hong Kong/2671/2019', 'A/Hong Kong/45/2019', 'A/Hong Kong/4801/2014',
    #     'A/Johannesburg/33/1994', 'A/Kansas/14/2017', 'A/Leningrad/360/1986',
    #     'A/Massachusetts/18/2022', 'A/Moscow/10/99', 'A/Perth/16/2009',
    #     'A/Philippines/2/1982', 'A/Shangdong/9/1993', 'A/Sichuan/2/1987',
    #     'A/Singapore/INFIMH-16-0019/2016', 'A/South Australia/34/2019',
    #     'A/Switzerland/8060/2017', 'A/Switzerland/9715293/2013',
    #     'A/Sydney/5/1997',
    #     'A/Texas/50/2012', 'A/Thailand/8/2022', 'A/Victoria/361/2011',
    #     'A/Wellington/1/2004', 'A/Wisconsin/67/2005', 'A/Wuhan/359/1995'
    # ]
    #
    # vaccine_count = sum(1 for name in virus_names if name in special_viruses)
    # total_count = len(virus_names)






    # # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
    # colors = [
    #     '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
    #     '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'
    # ]
    #
    # # åˆ›å»ºæ¤­åœ†æ ‡è®°
    # import matplotlib.path as mpath
    # import matplotlib.transforms as mtransforms
    # import numpy as np
    #
    # ellipse_path = mpath.Path.unit_circle()
    # transform = mtransforms.Affine2D().scale(1, 0.5)
    # ellipse_path = transform.transform_path(ellipse_path)
    #
    # # åˆ›å»ºç®€åŒ–çš„t-SNEå¯è§†åŒ–
    # plt.figure(figsize=(8, 8))
    #
    # # å…ˆç»˜åˆ¶æ•°æ®ç‚¹
    # # ç»˜åˆ¶åŸå§‹ç‰¹å¾ï¼ˆåœ†å½¢æ ‡è®°ï¼‰
    # for i in range(num_clusters):
    #     mask = original_clusters == i
    #     plt.scatter(
    #         original_2d[mask, 0], original_2d[mask, 1],
    #         c=[colors[i % len(colors)]], alpha=0.7, s=100,
    #         edgecolors='white', linewidths=0.5, marker='o', zorder=2
    #     )
    #
    # # ç»˜åˆ¶å»å™ªç‰¹å¾ï¼ˆæ¤­åœ†æ ‡è®°ï¼‰ï¼Œä½†ä½¿ç”¨original_clustersæ¥å†³å®šé¢œè‰²
    # for i in range(num_clusters):
    #     mask = original_clusters == i  # ä½¿ç”¨åŸå§‹èšç±»ç»“æœæ¥ç­›é€‰ç‚¹
    #     plt.scatter(
    #         denoised_2d[mask, 0], denoised_2d[mask, 1],  # ç»˜åˆ¶å»å™ªç‰¹å¾çš„åæ ‡
    #         c=[colors[i % len(colors)]], alpha=0.9, s=120,  # ä½¿ç”¨ä¸åŸå§‹ç‰¹å¾ç›¸åŒçš„é¢œè‰²
    #         edgecolors='black', linewidths=0.5, marker=ellipse_path, zorder=3
    #     )
    #
    # # è·å–å½“å‰åæ ‡è½´å’Œè¾¹ç•Œ
    # ax = plt.gca()
    # xlim = ax.get_xlim()
    # ylim = ax.get_ylim()
    #
    # # æ‰‹åŠ¨ç»˜åˆ¶ç½‘æ ¼çº¿ï¼Œåˆ›å»º10x10çš„ç½‘æ ¼
    # x_ticks = np.linspace(xlim[0], xlim[1], 10)
    # y_ticks = np.linspace(ylim[0], ylim[1], 10)
    #
    # # ç»˜åˆ¶å‚ç›´ç½‘æ ¼çº¿ï¼ˆåœ¨æ‰€æœ‰å›¾å½¢å…ƒç´ ä¹‹å‰ï¼Œæ‰€ä»¥zorder=0ï¼‰
    # for x in x_ticks:
    #     plt.axvline(x=x, color='gray', linestyle='--', alpha=0.5, zorder=0)
    #
    # # ç»˜åˆ¶æ°´å¹³ç½‘æ ¼çº¿
    # for y in y_ticks:
    #     plt.axhline(y=y, color='gray', linestyle='--', alpha=0.5, zorder=0)
    #
    # # ç§»é™¤åˆ»åº¦ä½†ä¿ç•™åæ ‡è½´
    # plt.tick_params(axis='both', which='both', length=0)
    # plt.xticks([])
    # plt.yticks([])
    #
    # # åˆ›å»ºå›¾ä¾‹æ¡ç›®
    # from matplotlib.lines import Line2D
    #
    # legend_elements = [
    #     Line2D([0], [0], marker='o', color='white', label='Original Features',
    #            markerfacecolor='black', markersize=10, alpha=0.7),
    #     Line2D([0], [0], marker=ellipse_path, color='white',
    #            label='Denoised Features',
    #            markerfacecolor='black', markersize=10, alpha=0.9)
    # ]
    #
    # plt.suptitle('H1N1', fontsize=14)
    # plt.legend(handles=legend_elements, loc='upper right')
    #
    # # ä¿å­˜å›¾å½¢
    # plt.savefig('tsne_simplified.pdf', dpi=600, bbox_inches='tight',
    #             transparent=True)
    # plt.show()
    # åˆ›å»ºç»„åˆè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼ˆåªæœ‰åŸå§‹æ•°æ®ï¼‰
    combined_train_data, test_data, diffusion_offset = create_combined_training_data(
        data=data,
        denoised_features=denoised_features,
        train_indices=train_idx,
        test_indices=test_idx,
        device=device
    )

    # åˆ›å»ºç»„åˆç‰¹å¾æ˜ å°„
    combined_node_to_feature = create_combined_feature_mapping(
        data=data,
        denoised_features=denoised_features,
        diffusion_offset=diffusion_offset,
        device=device
    )

    # é˜¶æ®µ2ï¼šè®­ç»ƒè·ç¦»é¢„æµ‹å™¨ - ä½¿ç”¨ç»„åˆæ•°æ®
    predictor_optimizer = optim.Adam(
        model.distance_predictor.parameters(),
        lr=1e-3,
        weight_decay=1e-5
    )
    predictor_scheduler = CosineAnnealingLR(predictor_optimizer,
                                            T_max=predictor_epochs,
                                            eta_min=1e-6)

    # ä½¿ç”¨ç»„åˆæ•°æ®è®­ç»ƒè·ç¦»é¢„æµ‹å™¨ï¼Œä½†ä»…ä½¿ç”¨åŸå§‹æ•°æ®æµ‹è¯•
    model = train_distance_predictor_with_combined_data(
        model=model,
        combined_train_data=combined_train_data,
        test_data=test_data,  # åªåŒ…å«åŸå§‹æ•°æ®çš„æµ‹è¯•é›†
        node_to_feature=combined_node_to_feature,
        device=device,
        optimizer=predictor_optimizer,
        batch_size=batch_size,
        num_epochs=predictor_epochs,
        scheduler=predictor_scheduler
    )
    checkpoint = torch.load("best_distance_predictor_by_train.pt")
    model.load_state_dict(checkpoint['model_state_dict'])
    # è¯„ä¼°æœ€ç»ˆæ¨¡å‹ - ä»…è¯„ä¼°åœ¨åŸå§‹æ•°æ®æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½
    mae, mse, r2 = evaluate_model_with_combined_data(
        model=model,
        combined_test_data=test_data,  # åªåŒ…å«åŸå§‹æ•°æ®çš„æµ‹è¯•é›†
        node_to_feature=combined_node_to_feature,
        device=device,
        batch_size=batch_size,
        plot_correlation=True,  # æ·»åŠ è¿™ä¸ªå‚æ•°å¯ç”¨æ•£ç‚¹å›¾ç»˜åˆ¶
        save_path="final_model_correlation.pdf"
    )

    print(
        f"Final model evaluation - MAE: {mae:.6f}, MSE: {mse:.6f}, RÂ²: {r2:.4f}")

    # ä¿å­˜å®Œæ•´æ¨¡å‹
    torch.save(model.state_dict(), "final_node_diffusion_model.pt")
    print("Training complete. Final model saved.")